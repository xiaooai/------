{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from d2l import torch as d2l\n",
    "d2l.DATA_HUB['banana-detection'] = (\n",
    "    d2l.DATA_URL + 'banana-detection.zip',\n",
    "    '5de26c8fce5ccdea9f91267273464dc968d20d72')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_bananas(is_train=True):\n",
    "    \"\"\"读取香蕉检测数据集中的图像和标签\"\"\"\n",
    "    data_dir = d2l.download_extract('banana-detection')\n",
    "    csv_fname = os.path.join(data_dir, 'bananas_train' if is_train\n",
    "                        else 'bananas_val', 'label.csv')\n",
    "    csv_data = pd.read_csv(csv_fname)\n",
    "    csv_data = csv_data.set_index('img_name')\n",
    "    images, targets = [], []\n",
    "    for img_name, target in csv_data.iterrows():\n",
    "        images.append(torchvision.io.read_image(\n",
    "            os.path.join(data_dir, 'bananas_train' if is_train else\n",
    "                        'bananas_val', 'images', f'{img_name}')))\n",
    "        # 这里的target包含（类别，左上角x，左上角y，右下角x，右下角y），\n",
    "        # 其中所有图像都具有相同的香蕉类（索引为0）\n",
    "        targets.append(list(target))\n",
    "    return images, torch.tensor(targets).unsqueeze(1) / 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BananasDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"一个用于加载香蕉检测数据集的自定义数据集\"\"\"\n",
    "    def __init__(self, is_train):\n",
    "        self.features, self.labels = read_data_bananas(is_train)\n",
    "        print('read ' + str(len(self.features)) + (f' training examples' if\n",
    "            is_train else f' validation examples'))\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.features[idx].float(), self.labels[idx])\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_bananas(batch_size):\n",
    "    \"\"\"加载香蕉检测数据集\"\"\"\n",
    "    train_iter = torch.utils.data.DataLoader(BananasDataset(is_train=True),\n",
    "                                    batch_size, shuffle=True)\n",
    "    val_iter = torch.utils.data.DataLoader(BananasDataset(is_train=False),\n",
    "                                    batch_size)\n",
    "    return train_iter, val_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, edge_size = 32, 256\n",
    "train_iter, _ = load_data_bananas(batch_size)\n",
    "batch = next(iter(train_iter))\n",
    "batch[0].shape, batch[1].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = (batch[0][0:10].permute(0, 2, 3, 1)) / 255\n",
    "axes = d2l.show_images(imgs, 2, 5, scale=2)\n",
    "for ax, label in zip(axes, batch[1][0:10]):\n",
    "    d2l.show_bboxes(ax, [label[0][1:5] * edge_size], colors=['w'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 单发多框检测SSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from d2l import torch as d2l\n",
    "\n",
    "\n",
    "def cls_predictor(num_inputs, num_anchors, num_classes):\n",
    "    return nn.Conv2d(num_inputs, num_anchors * (num_classes + 1),\n",
    "                    kernel_size=3, padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x, block):\n",
    "    return block(x)\n",
    "\n",
    "Y1 = forward(torch.zeros((2, 8, 20, 20)), cls_predictor(8, 5, 10))\n",
    "Y2 = forward(torch.zeros((2, 16, 10, 10)), cls_predictor(16, 3, 10))\n",
    "Y1.shape, Y2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_pred(pred):\n",
    "    return torch.flatten(pred.permute(0, 2, 3, 1), start_dim=1)\n",
    "\n",
    "def concat_preds(preds):\n",
    "    return torch.cat([flatten_pred(p) for p in preds], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_preds([Y1, Y2]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_sample_blk(in_channels, out_channels):\n",
    "    blk = []\n",
    "    for _ in range(2):\n",
    "        blk.append(nn.Conv2d(in_channels, out_channels,\n",
    "            kernel_size=3, padding=1))\n",
    "        blk.append(nn.BatchNorm2d(out_channels))\n",
    "        blk.append(nn.ReLU())\n",
    "        in_channels = out_channels\n",
    "    blk.append(nn.MaxPool2d(2))\n",
    "    return nn.Sequential(*blk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward(torch.zeros((2, 3, 20, 20)), down_sample_blk(3, 10)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_net():\n",
    "    blk = []\n",
    "    num_filters = [3, 16, 32, 64]\n",
    "    for i in range(len(num_filters) - 1):\n",
    "        blk.append(down_sample_blk(num_filters[i], num_filters[i+1]))\n",
    "    return nn.Sequential(*blk)\n",
    "\n",
    "forward(torch.zeros((2, 3, 256, 256)), base_net()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blk(i):\n",
    "    if i == 0:\n",
    "        blk = base_net()\n",
    "    elif i == 1:\n",
    "        blk = down_sample_blk(64, 128)\n",
    "    elif i == 4:\n",
    "        blk = nn.AdaptiveMaxPool2d((1,1))\n",
    "    else:\n",
    "        blk = down_sample_blk(128, 128)\n",
    "    return blk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blk_forward(X, blk, size, ratio, cls_predictor, bbox_predictor):\n",
    "    Y = blk(X)\n",
    "    anchors = d2l.multibox_prior(Y, sizes=size, ratios=ratio)\n",
    "    cls_preds = cls_predictor(Y)\n",
    "    bbox_preds = bbox_predictor(Y)\n",
    "    return (Y, anchors, cls_preds, bbox_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [[0.2, 0.272], [0.37, 0.447], [0.54, 0.619], [0.71, 0.79],\n",
    "        [0.88, 0.961]]\n",
    "ratios = [[1, 2, 0.5]] * 5\n",
    "num_anchors = len(sizes[0]) + len(ratios[0]) - 1\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
